===============================
1498070.pbshpc
vsky016.hpc.iitd.ac.in
===============================
/home/cse/phd/anz208849/IAST_update
pretrained fc.weight are not used as initial params.
pretrained fc.bias are not used as initial params.
pretrained fc.weight are not used as initial params.
pretrained fc.bias are not used as initial params.
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/home/cse/phd/anz208849/anaconda3/envs/IAST/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda12device_countEv')
DATASET:
  ANNS: ../data/cityscapes_train2.json
  IMAGEDIR: ../../scratch/data/cityscapes
  NUM_WORKER: 2
  RESIZE_SIZE: []
  TARGET:
    ANNS: ../data/darkzurich_train.json
    IMAGEDIR: ../../scratch/data/dark_zurich
    ORIGIN_SIZE: [1920, 1080]
    PSEUDO_BATCH_SIZE: 2
    PSEUDO_LOSS_WEIGHT: 1.0
    PSEUDO_PL: IAST
    PSEUDO_PL_ALPHA: 0.2
    PSEUDO_PL_BETA: 0.9
    PSEUDO_PL_GAMMA: 1.0
    PSEUDO_SAVE_DIR: 
    PSEUDO_SIZE: [1280, 640]
    SKIP_GEN_PSEUDO: False
    SOURCE_LOSS_WEIGHT: 1.0
    TYPE: MsDarkzurichDataset
  TYPE: MsCityscapesDataset
  USE_AUG: True
  VAL:
    ANNS: ../data/darkzurich_val.json
    IMAGEDIR: ../../scratch/data/dark_zurich_val
    ORIGIN_SIZE: [1920, 1080]
    RESIZE_SIZE: [1920, 1080]
    TYPE: DarkzurichDataset
MODEL:
  BACKBONE:
    PRETRAINED: True
    TYPE: R-DL-101-C1-C5-FREEZEBN
    WITH_IBN: False
  DECODER:
    TYPE: DeepLabV2Dedoder
  DISCRIMINATOR:
    LAMBDA_ENTROPY_WEIGHT: 0.0
    LAMBDA_KLDREG_WEIGHT: 0.0
    LOSS: MSELoss
    LR: [2e-05]
    TYPE: ['Origin-Predictor']
    UPDATE_T: 1.0
    WEIGHT: [0.05]
  PREDICTOR:
    LOSS: CrossEntropy
    NUM_CLASSES: 19
    TYPE: UpsamplePredictor
  TYPE: UDA_Segmentor
RANDOM_SEED: 888
TEST:
  BATCH_SIZE: 1
  NUM_WORKER: 2
  N_PROC_PER_NODE: 1
  RESIZE_SIZE: [[1280, 640]]
  USE_FLIP: False
TRAIN:
  APEX_OPT: O1
  BATCHSIZE: 4
  COSINEANNEALINGLR:
    T_MAX: 4
    T_MULT: 1.0
  EARLY_STOPPING: -1
  EPOCHES: 10
  ITER_REPORT: 100
  ITER_VAL: 600
  LR: 2e-05
  N_PROC_PER_NODE: 1
  OPTIMIZER: Adam
  PSEUDO_RESUME_FROM: 
  RESUME_FROM: ../../saved_models/IAST_update/source_only/best_iter.pth
  SAVE_ALL: False
  SCHEDULER: CosineAnnealingLR_with_Restart
WORK_DIR: ../../saved_models/IAST_update/warmup_at
resume from epoch 0 iter 100
Start training!
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
eta: 4h 19min, epoch: 1, iter: 200 , time: 2.153 s/iter, lr: 1.98e-05, D_lr: 1.98e-05, loss: 1.656298, D_Origin-Predictor_loss: 0.290385, mask_loss: 1.656298
eta: 4h 15min, epoch: 1, iter: 300 , time: 2.153 s/iter, lr: 1.95e-05, D_lr: 1.95e-05, loss: 0.970462, D_Origin-Predictor_loss: 0.227933, mask_loss: 0.970462
eta: 4h 12min, epoch: 1, iter: 400 , time: 2.153 s/iter, lr: 1.91e-05, D_lr: 1.91e-05, loss: 0.802935, D_Origin-Predictor_loss: 0.209917, mask_loss: 0.802935
eta: 4h 08min, epoch: 1, iter: 500 , time: 2.154 s/iter, lr: 1.86e-05, D_lr: 1.86e-05, loss: 0.772403, D_Origin-Predictor_loss: 0.205832, mask_loss: 0.772403
eta: 4h 05min, epoch: 1, iter: 600 , time: 2.153 s/iter, lr: 1.81e-05, D_lr: 1.81e-05, loss: 0.674588, D_Origin-Predictor_loss: 0.204988, mask_loss: 0.674588
epoch: 1, val_miou: 0.0957(0.0957), 0: 0.3309, 1: 0.1698, 2: 0.4049, 3: 0.0098, 4: 0.0383, 5: 0.0433, 6: 0.0127, 7: 0.0169, 8: 0.3282, 9: 0.0916, 10: 0.0054, 11: 0.0617, 12: 0.0000, 13: 0.2949, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0100
eta: 4h 01min, epoch: 1, iter: 700 , time: 2.154 s/iter, lr: 1.74e-05, D_lr: 1.74e-05, loss: 0.635524, D_Origin-Predictor_loss: 0.208466, mask_loss: 0.635524
eta: 4h 03min, epoch: 1, iter: 800 , time: 2.206 s/iter, lr: 1.66e-05, D_lr: 1.66e-05, loss: 0.625051, D_Origin-Predictor_loss: 0.212069, mask_loss: 0.625051
eta: 4h 00min, epoch: 2, iter: 900 , time: 2.209 s/iter, lr: 1.58e-05, D_lr: 1.58e-05, loss: 0.573381, D_Origin-Predictor_loss: 0.206558, mask_loss: 0.573381
eta: 3h 50min, epoch: 2, iter: 1000 , time: 2.155 s/iter, lr: 1.49e-05, D_lr: 1.49e-05, loss: 0.582419, D_Origin-Predictor_loss: 0.206488, mask_loss: 0.582419
eta: 3h 47min, epoch: 2, iter: 1100 , time: 2.154 s/iter, lr: 1.40e-05, D_lr: 1.40e-05, loss: 0.526352, D_Origin-Predictor_loss: 0.206011, mask_loss: 0.526352
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
eta: 3h 43min, epoch: 2, iter: 1200 , time: 2.153 s/iter, lr: 1.30e-05, D_lr: 1.30e-05, loss: 0.554877, D_Origin-Predictor_loss: 0.207225, mask_loss: 0.554877
epoch: 2, val_miou: 0.1221(0.1221), 0: 0.3719, 1: 0.2203, 2: 0.4836, 3: 0.0261, 4: 0.1059, 5: 0.0991, 6: 0.0458, 7: 0.0305, 8: 0.3458, 9: 0.1167, 10: 0.0066, 11: 0.0801, 12: 0.0092, 13: 0.3587, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0005, 18: 0.0186
eta: 3h 40min, epoch: 2, iter: 1300 , time: 2.156 s/iter, lr: 1.20e-05, D_lr: 1.20e-05, loss: 0.527891, D_Origin-Predictor_loss: 0.207096, mask_loss: 0.527891
eta: 3h 42min, epoch: 2, iter: 1400 , time: 2.216 s/iter, lr: 1.09e-05, D_lr: 1.09e-05, loss: 0.509436, D_Origin-Predictor_loss: 0.208572, mask_loss: 0.509436
eta: 3h 32min, epoch: 2, iter: 1500 , time: 2.154 s/iter, lr: 9.86e-06, D_lr: 9.86e-06, loss: 0.492442, D_Origin-Predictor_loss: 0.208525, mask_loss: 0.492442
eta: 3h 34min, epoch: 3, iter: 1600 , time: 2.205 s/iter, lr: 8.81e-06, D_lr: 8.81e-06, loss: 0.485957, D_Origin-Predictor_loss: 0.210315, mask_loss: 0.485957
eta: 3h 25min, epoch: 3, iter: 1700 , time: 2.154 s/iter, lr: 7.77e-06, D_lr: 7.77e-06, loss: 0.474340, D_Origin-Predictor_loss: 0.205332, mask_loss: 0.474340
eta: 3h 22min, epoch: 3, iter: 1800 , time: 2.154 s/iter, lr: 6.75e-06, D_lr: 6.75e-06, loss: 0.453958, D_Origin-Predictor_loss: 0.208118, mask_loss: 0.453958
epoch: 3, val_miou: 0.1299(0.1299), 0: 0.4128, 1: 0.2710, 2: 0.4578, 3: 0.0454, 4: 0.0995, 5: 0.1033, 6: 0.0328, 7: 0.0450, 8: 0.3504, 9: 0.1583, 10: 0.0143, 11: 0.0967, 12: 0.0120, 13: 0.3500, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0177
eta: 3h 18min, epoch: 3, iter: 1900 , time: 2.158 s/iter, lr: 5.78e-06, D_lr: 5.78e-06, loss: 0.463684, D_Origin-Predictor_loss: 0.208740, mask_loss: 0.463684
eta: 3h 20min, epoch: 3, iter: 2000 , time: 2.217 s/iter, lr: 4.85e-06, D_lr: 4.85e-06, loss: 0.487020, D_Origin-Predictor_loss: 0.210821, mask_loss: 0.487020
eta: 3h 12min, epoch: 3, iter: 2100 , time: 2.162 s/iter, lr: 3.97e-06, D_lr: 3.97e-06, loss: 0.437425, D_Origin-Predictor_loss: 0.211599, mask_loss: 0.437425
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
eta: 3h 08min, epoch: 3, iter: 2200 , time: 2.160 s/iter, lr: 3.17e-06, D_lr: 3.17e-06, loss: 0.454254, D_Origin-Predictor_loss: 0.209959, mask_loss: 0.454254
eta: 3h 04min, epoch: 3, iter: 2300 , time: 2.161 s/iter, lr: 2.44e-06, D_lr: 2.44e-06, loss: 0.438778, D_Origin-Predictor_loss: 0.210930, mask_loss: 0.438778
eta: 3h 06min, epoch: 4, iter: 2400 , time: 2.223 s/iter, lr: 1.79e-06, D_lr: 1.79e-06, loss: 0.432994, D_Origin-Predictor_loss: 0.210260, mask_loss: 0.432994
epoch: 4, val_miou: 0.1381(0.1381), 0: 0.4334, 1: 0.2944, 2: 0.4721, 3: 0.0416, 4: 0.1534, 5: 0.1218, 6: 0.0194, 7: 0.0523, 8: 0.3490, 9: 0.1575, 10: 0.0066, 11: 0.1101, 12: 0.0085, 13: 0.3804, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0005, 18: 0.0224
eta: 2h 57min, epoch: 4, iter: 2500 , time: 2.161 s/iter, lr: 1.24e-06, D_lr: 1.24e-06, loss: 0.480126, D_Origin-Predictor_loss: 0.207952, mask_loss: 0.480126
eta: 2h 58min, epoch: 4, iter: 2600 , time: 2.217 s/iter, lr: 7.82e-07, D_lr: 7.82e-07, loss: 0.435077, D_Origin-Predictor_loss: 0.209256, mask_loss: 0.435077
eta: 2h 50min, epoch: 4, iter: 2700 , time: 2.161 s/iter, lr: 4.30e-07, D_lr: 4.30e-07, loss: 0.469924, D_Origin-Predictor_loss: 0.214251, mask_loss: 0.469924
eta: 2h 46min, epoch: 4, iter: 2800 , time: 2.161 s/iter, lr: 1.85e-07, D_lr: 1.85e-07, loss: 0.445516, D_Origin-Predictor_loss: 0.211083, mask_loss: 0.445516
eta: 2h 43min, epoch: 4, iter: 2900 , time: 2.163 s/iter, lr: 4.89e-08, D_lr: 4.89e-08, loss: 0.438459, D_Origin-Predictor_loss: 0.207759, mask_loss: 0.438459
eta: 2h 39min, epoch: 4, iter: 3000 , time: 2.161 s/iter, lr: 2.00e-05, D_lr: 2.00e-05, loss: 0.444426, D_Origin-Predictor_loss: 0.211619, mask_loss: 0.444426
epoch: 4, val_miou: 0.1214(0.1381), 0: 0.3552, 1: 0.2189, 2: 0.4520, 3: 0.0314, 4: 0.1265, 5: 0.1107, 6: 0.0058, 7: 0.0411, 8: 0.3384, 9: 0.1343, 10: 0.0095, 11: 0.1115, 12: 0.0048, 13: 0.3501, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0164
eta: 2h 40min, epoch: 5, iter: 3100 , time: 2.217 s/iter, lr: 1.99e-05, D_lr: 1.99e-05, loss: 0.440818, D_Origin-Predictor_loss: 0.214348, mask_loss: 0.440818
eta: 2h 36min, epoch: 5, iter: 3200 , time: 2.217 s/iter, lr: 1.97e-05, D_lr: 1.97e-05, loss: 0.433751, D_Origin-Predictor_loss: 0.217413, mask_loss: 0.433751
eta: 2h 28min, epoch: 5, iter: 3300 , time: 2.161 s/iter, lr: 1.94e-05, D_lr: 1.94e-05, loss: 0.426595, D_Origin-Predictor_loss: 0.213230, mask_loss: 0.426595
eta: 2h 25min, epoch: 5, iter: 3400 , time: 2.163 s/iter, lr: 1.90e-05, D_lr: 1.90e-05, loss: 0.427721, D_Origin-Predictor_loss: 0.221188, mask_loss: 0.427721
eta: 2h 21min, epoch: 5, iter: 3500 , time: 2.160 s/iter, lr: 1.85e-05, D_lr: 1.85e-05, loss: 0.402886, D_Origin-Predictor_loss: 0.219126, mask_loss: 0.402886
eta: 2h 18min, epoch: 5, iter: 3600 , time: 2.162 s/iter, lr: 1.79e-05, D_lr: 1.79e-05, loss: 0.393315, D_Origin-Predictor_loss: 0.217738, mask_loss: 0.393315
epoch: 5, val_miou: 0.1492(0.1492), 0: 0.4206, 1: 0.3145, 2: 0.4955, 3: 0.0784, 4: 0.1147, 5: 0.1323, 6: 0.0695, 7: 0.0576, 8: 0.3478, 9: 0.2098, 10: 0.0072, 11: 0.1011, 12: 0.0107, 13: 0.4301, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0453
eta: 2h 14min, epoch: 5, iter: 3700 , time: 2.161 s/iter, lr: 1.72e-05, D_lr: 1.72e-05, loss: 0.386587, D_Origin-Predictor_loss: 0.218026, mask_loss: 0.386587
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
eta: 2h 13min, epoch: 5, iter: 3800 , time: 2.213 s/iter, lr: 1.64e-05, D_lr: 1.64e-05, loss: 0.371729, D_Origin-Predictor_loss: 0.219432, mask_loss: 0.371729
eta: 2h 10min, epoch: 6, iter: 3900 , time: 2.221 s/iter, lr: 1.56e-05, D_lr: 1.56e-05, loss: 0.384000, D_Origin-Predictor_loss: 0.223646, mask_loss: 0.384000
eta: 2h 03min, epoch: 6, iter: 4000 , time: 2.160 s/iter, lr: 1.47e-05, D_lr: 1.47e-05, loss: 0.361706, D_Origin-Predictor_loss: 0.220599, mask_loss: 0.361706
eta: 1h 59min, epoch: 6, iter: 4100 , time: 2.161 s/iter, lr: 1.37e-05, D_lr: 1.37e-05, loss: 0.350516, D_Origin-Predictor_loss: 0.220278, mask_loss: 0.350516
eta: 1h 56min, epoch: 6, iter: 4200 , time: 2.161 s/iter, lr: 1.27e-05, D_lr: 1.27e-05, loss: 0.375753, D_Origin-Predictor_loss: 0.222850, mask_loss: 0.375753
epoch: 6, val_miou: 0.1565(0.1565), 0: 0.4495, 1: 0.3463, 2: 0.5173, 3: 0.0693, 4: 0.1640, 5: 0.1518, 6: 0.0358, 7: 0.0639, 8: 0.3444, 9: 0.1892, 10: 0.0112, 11: 0.1279, 12: 0.0180, 13: 0.4245, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0076, 18: 0.0524
eta: 1h 52min, epoch: 6, iter: 4300 , time: 2.161 s/iter, lr: 1.17e-05, D_lr: 1.17e-05, loss: 0.366961, D_Origin-Predictor_loss: 0.224888, mask_loss: 0.366961
eta: 1h 52min, epoch: 6, iter: 4400 , time: 2.232 s/iter, lr: 1.06e-05, D_lr: 1.06e-05, loss: 0.357402, D_Origin-Predictor_loss: 0.222916, mask_loss: 0.357402
eta: 1h 45min, epoch: 6, iter: 4500 , time: 2.163 s/iter, lr: 9.57e-06, D_lr: 9.57e-06, loss: 0.348386, D_Origin-Predictor_loss: 0.223615, mask_loss: 0.348386
eta: 1h 44min, epoch: 7, iter: 4600 , time: 2.213 s/iter, lr: 8.52e-06, D_lr: 8.52e-06, loss: 0.335388, D_Origin-Predictor_loss: 0.223934, mask_loss: 0.335388
eta: 1h 38min, epoch: 7, iter: 4700 , time: 2.162 s/iter, lr: 7.48e-06, D_lr: 7.48e-06, loss: 0.364486, D_Origin-Predictor_loss: 0.222315, mask_loss: 0.364486
eta: 1h 34min, epoch: 7, iter: 4800 , time: 2.162 s/iter, lr: 6.48e-06, D_lr: 6.48e-06, loss: 0.330962, D_Origin-Predictor_loss: 0.222951, mask_loss: 0.330962
epoch: 7, val_miou: 0.1611(0.1611), 0: 0.5145, 1: 0.3795, 2: 0.5197, 3: 0.0758, 4: 0.1498, 5: 0.1627, 6: 0.0334, 7: 0.0709, 8: 0.3546, 9: 0.2065, 10: 0.0089, 11: 0.1250, 12: 0.0271, 13: 0.3750, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0058, 18: 0.0521
eta: 1h 31min, epoch: 7, iter: 4900 , time: 2.162 s/iter, lr: 5.51e-06, D_lr: 5.51e-06, loss: 0.358604, D_Origin-Predictor_loss: 0.226618, mask_loss: 0.358604
eta: 1h 29min, epoch: 7, iter: 5000 , time: 2.211 s/iter, lr: 4.59e-06, D_lr: 4.59e-06, loss: 0.339548, D_Origin-Predictor_loss: 0.219705, mask_loss: 0.339548
eta: 1h 23min, epoch: 7, iter: 5100 , time: 2.163 s/iter, lr: 3.74e-06, D_lr: 3.74e-06, loss: 0.342978, D_Origin-Predictor_loss: 0.222844, mask_loss: 0.342978
eta: 1h 20min, epoch: 7, iter: 5200 , time: 2.162 s/iter, lr: 2.95e-06, D_lr: 2.95e-06, loss: 0.321111, D_Origin-Predictor_loss: 0.221340, mask_loss: 0.321111
eta: 1h 16min, epoch: 7, iter: 5300 , time: 2.161 s/iter, lr: 2.25e-06, D_lr: 2.25e-06, loss: 0.325803, D_Origin-Predictor_loss: 0.225362, mask_loss: 0.325803
eta: 1h 15min, epoch: 8, iter: 5400 , time: 2.246 s/iter, lr: 1.63e-06, D_lr: 1.63e-06, loss: 0.334990, D_Origin-Predictor_loss: 0.224225, mask_loss: 0.334990
epoch: 8, val_miou: 0.1659(0.1659), 0: 0.5206, 1: 0.3902, 2: 0.5163, 3: 0.0879, 4: 0.1673, 5: 0.1667, 6: 0.0261, 7: 0.0736, 8: 0.3495, 9: 0.2305, 10: 0.0081, 11: 0.1268, 12: 0.0165, 13: 0.4169, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0040, 18: 0.0511
eta: 1h 09min, epoch: 8, iter: 5500 , time: 2.162 s/iter, lr: 1.10e-06, D_lr: 1.10e-06, loss: 0.323853, D_Origin-Predictor_loss: 0.220968, mask_loss: 0.323853
eta: 1h 07min, epoch: 8, iter: 5600 , time: 2.215 s/iter, lr: 6.73e-07, D_lr: 6.73e-07, loss: 0.325620, D_Origin-Predictor_loss: 0.219553, mask_loss: 0.325620
eta: 1h 02min, epoch: 8, iter: 5700 , time: 2.161 s/iter, lr: 3.50e-07, D_lr: 3.50e-07, loss: 0.343771, D_Origin-Predictor_loss: 0.222836, mask_loss: 0.343771
eta: 0h 58min, epoch: 8, iter: 5800 , time: 2.161 s/iter, lr: 1.36e-07, D_lr: 1.36e-07, loss: 0.321349, D_Origin-Predictor_loss: 0.220372, mask_loss: 0.321349
eta: 0h 55min, epoch: 8, iter: 5900 , time: 2.161 s/iter, lr: 3.08e-08, D_lr: 3.08e-08, loss: 0.321804, D_Origin-Predictor_loss: 0.223781, mask_loss: 0.321804
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
eta: 0h 51min, epoch: 8, iter: 6000 , time: 2.160 s/iter, lr: 2.00e-05, D_lr: 2.00e-05, loss: 0.351370, D_Origin-Predictor_loss: 0.224337, mask_loss: 0.351370
epoch: 8, val_miou: 0.1588(0.1659), 0: 0.5224, 1: 0.3382, 2: 0.5161, 3: 0.1022, 4: 0.0819, 5: 0.1643, 6: 0.0166, 7: 0.0706, 8: 0.3383, 9: 0.2115, 10: 0.0068, 11: 0.1262, 12: 0.0197, 13: 0.4475, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0015, 18: 0.0528
eta: 0h 49min, epoch: 9, iter: 6100 , time: 2.219 s/iter, lr: 1.99e-05, D_lr: 1.99e-05, loss: 0.325956, D_Origin-Predictor_loss: 0.227423, mask_loss: 0.325956
eta: 0h 45min, epoch: 9, iter: 6200 , time: 2.209 s/iter, lr: 1.96e-05, D_lr: 1.96e-05, loss: 0.336244, D_Origin-Predictor_loss: 0.223273, mask_loss: 0.336244
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
eta: 0h 40min, epoch: 9, iter: 6300 , time: 2.160 s/iter, lr: 1.93e-05, D_lr: 1.93e-05, loss: 0.327167, D_Origin-Predictor_loss: 0.224259, mask_loss: 0.327167
eta: 0h 37min, epoch: 9, iter: 6400 , time: 2.162 s/iter, lr: 1.89e-05, D_lr: 1.89e-05, loss: 0.340271, D_Origin-Predictor_loss: 0.229400, mask_loss: 0.340271
eta: 0h 33min, epoch: 9, iter: 6500 , time: 2.161 s/iter, lr: 1.83e-05, D_lr: 1.83e-05, loss: 0.305768, D_Origin-Predictor_loss: 0.224176, mask_loss: 0.305768
eta: 0h 29min, epoch: 9, iter: 6600 , time: 2.161 s/iter, lr: 1.77e-05, D_lr: 1.77e-05, loss: 0.310899, D_Origin-Predictor_loss: 0.228109, mask_loss: 0.310899
epoch: 9, val_miou: 0.1524(0.1659), 0: 0.4277, 1: 0.3468, 2: 0.4861, 3: 0.0738, 4: 0.1377, 5: 0.1497, 6: 0.0282, 7: 0.0812, 8: 0.3424, 9: 0.1881, 10: 0.0068, 11: 0.1255, 12: 0.0448, 13: 0.3871, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0027, 18: 0.0664
eta: 0h 26min, epoch: 9, iter: 6700 , time: 2.160 s/iter, lr: 1.70e-05, D_lr: 1.70e-05, loss: 0.317516, D_Origin-Predictor_loss: 0.230236, mask_loss: 0.317516
eta: 0h 23min, epoch: 10, iter: 6800 , time: 2.272 s/iter, lr: 1.62e-05, D_lr: 1.62e-05, loss: 0.321891, D_Origin-Predictor_loss: 0.231359, mask_loss: 0.321891
eta: 0h 19min, epoch: 10, iter: 6900 , time: 2.161 s/iter, lr: 1.53e-05, D_lr: 1.53e-05, loss: 0.315015, D_Origin-Predictor_loss: 0.230114, mask_loss: 0.315015
eta: 0h 15min, epoch: 10, iter: 7000 , time: 2.162 s/iter, lr: 1.44e-05, D_lr: 1.44e-05, loss: 0.309847, D_Origin-Predictor_loss: 0.227769, mask_loss: 0.309847
eta: 0h 11min, epoch: 10, iter: 7100 , time: 2.161 s/iter, lr: 1.34e-05, D_lr: 1.34e-05, loss: 0.306559, D_Origin-Predictor_loss: 0.224892, mask_loss: 0.306559
eta: 0h 08min, epoch: 10, iter: 7200 , time: 2.160 s/iter, lr: 1.24e-05, D_lr: 1.24e-05, loss: 0.313799, D_Origin-Predictor_loss: 0.226309, mask_loss: 0.313799
epoch: 10, val_miou: 0.1679(0.1679), 0: 0.5051, 1: 0.3900, 2: 0.5088, 3: 0.0887, 4: 0.1702, 5: 0.1450, 6: 0.0153, 7: 0.0842, 8: 0.3402, 9: 0.2156, 10: 0.0073, 11: 0.1301, 12: 0.0550, 13: 0.4682, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0015, 18: 0.0643
eta: 0h 04min, epoch: 10, iter: 7300 , time: 2.162 s/iter, lr: 1.14e-05, D_lr: 1.14e-05, loss: 0.287217, D_Origin-Predictor_loss: 0.226817, mask_loss: 0.287217
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
eta: 0h 01min, epoch: 10, iter: 7400 , time: 2.223 s/iter, lr: 1.03e-05, D_lr: 1.03e-05, loss: 0.311398, D_Origin-Predictor_loss: 0.228883, mask_loss: 0.311398
End! epoch0 max metrics: 0.1679
